Attention Mechanism in LSTM
=========================

1. Input to Attention
-------------------
LSTM Output Shape: [batch_size, seq_len, hidden_size]
Example: [32, 100, 64] where:
- 32: batch size
- 100: sequence length (time steps)
- 64: hidden size (features per time step)

2. Attention Layers
-----------------
a) First Linear Layer (64 → 64):
   - Input: [batch_size, seq_len, 64]
   - Output: [batch_size, seq_len, 64]
   - Purpose: Transform LSTM outputs into attention features

b) Tanh Activation:
   - Input: [batch_size, seq_len, 64]
   - Output: [batch_size, seq_len, 64]
   - Purpose: Normalize values between -1 and 1

c) Second Linear Layer (64 → 1):
   - Input: [batch_size, seq_len, 64]
   - Output: [batch_size, seq_len, 1]
   - Purpose: Generate attention scores

d) Softmax (dim=1):
   - Input: [batch_size, seq_len, 1]
   - Output: [batch_size, seq_len, 1]
   - Purpose: Convert scores to probabilities that sum to 1

3. Attention Process
------------------
For each sequence:
1. LSTM outputs: [100, 64] (100 time steps, 64 features each)
2. First Linear: Transform each time step
3. Tanh: Normalize values
4. Second Linear: Generate attention scores
5. Softmax: Convert to probabilities

Example:
Time Steps → Attention Weights
t1 → 0.1
t2 → 0.2
t3 → 0.4
t4 → 0.2
t5 → 0.1
...
t100 → 0.0

4. Context Vector
---------------
- Multiply attention weights by LSTM outputs
- Sum across time steps
- Result: [batch_size, 64]

5. Real-world Example
-------------------
Well Sensor Data:
- LSTM processes 100 time steps
- Each step has 64 features
- Attention might focus on:
  * Recent readings (higher weights)
  * Significant changes (higher weights)
  * Stable periods (lower weights)

6. Parameter Count
----------------
First Linear Layer:
- Weights: 64 × 64 = 4,096
- Bias: 64
- Total: 4,160

Second Linear Layer:
- Weights: 64 × 1 = 64
- Bias: 1
- Total: 65

Total Parameters: 4,225

7. Benefits
----------
- Model can focus on important time steps
- Learns which parts of sequence are relevant
- Handles long sequences better
- Adapts to different patterns in data 